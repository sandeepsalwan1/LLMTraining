# Asymptote AI: Gemma 3 for Code Generation

This project aims to leverage Google's Gemma 3 language models, optimized with Unsloth, to generate Asymptote vector graphics code. It features a script to build custom Asymptote code-image datasets and a framework for model fine-tuning and inference.

## Core Features

*   **Asymptote Dataset Builder (`makeDataset.py`):**
    *   Automatically processes `.asy` files from a user-provided directory (e.g., `asymptote-exemples/`, which can be populated from any Asymptote source).
    *   Compiles 2D Asymptote code to PNG images (output to `asy_images/`).
    *   Creates `asymp_dataset.json`: a dataset of (instruction, image_path, Asymptote_code) records, crucial for training image-to-code models.
*   **Gemma 3 Model Interaction:**
    *   Utilizes Unsloth for efficient loading of Gemma 3 models (e.g., `unsloth/gemma-3-4b-it` for initial tests, with plans for `unsloth/gemma-3-27b-it`).
    *   `Inference.py` / `Inference.ipynb`: Scripts for interactive model querying, set up with a multimodal input approach.
    *   `gemma3Training.py`: Base script for fine-tuning the model.

## Project Structure

sandeepsalwan1-llmtraining/
├── README.md
├── config.asy          # Asymptote configuration (e.g., texpath)
├── gemma3Training.py   # For Gemma 3 model training (adapt for multimodal)
├── Inference.ipynb     # Jupyter Notebook for model inference
├── Inference.py        # Python script for model inference
├── LICENSE
├── makeDataset.py      # Builds the Asymptote code-image dataset
├── asy_images/         # Output for images rendered by makeDataset.py
└── tests/              # Directory for test scripts (user-defined)
# User should create and populate:
# └── asymptote-exemples/ # Place source .asy files here
# Generated by makeDataset.py:
# └── asymp_dataset.json

code


## Setup

### Prerequisites

1.  **Python 3.x**
2.  **Asymptote:** Installed and in system PATH. ([https://asymptote.sourceforge.io/](https://asymptote.sourceforge.io/))
3.  **TeX Distribution:** For Asymptote's label typesetting (e.g., TeX Live).
    *   Adjust `texpath` in `makeDataset.py` or `config.asy` if needed.
4.  **Python Packages:**
    *   `Pillow`
    *   `unsloth`, `torch`, `transformers` (see Unsloth docs for specific environment setup: [https://github.com/unslothai/unsloth](https://github.com/unslothai/unsloth))

    Example:
    ```bash
    pip install Pillow
    pip install "unsloth[cu121] @ git+https://github.com/unslothai/unsloth.git" # Adjust for your CUDA
    ```

## Usage

### 1. Build Asymptote Code-Image Dataset

1.  Create `asymptote-exemples/` and fill it with `.asy` files.
2.  Verify/adjust `texpath` in `makeDataset.py` or `config.asy`.
3.  Run:
    ```bash
    python makeDataset.py
    ```
    Find output images in `asy_images/` and the dataset in `asymp_dataset.json`.

### 2. Gemma 3 Model Interaction & Training

*   **Inference (`Inference.py` / `Inference.ipynb`):**
    *   Run these scripts to interact with a loaded Gemma 3 model. Requires a suitable model if using image inputs.
*   **Training (`gemma3Training.py`):**
    *   This script is the starting point for fine-tuning.
    *   **To Do:** Adapt it to load `asymp_dataset.json` and perform multimodal (image + code) fine-tuning.

## Future Development & Improvements

*   **Upgrade Model:** Fine-tune a larger model like `unsloth/gemma-3-27b-it` for better performance (may require paid GPU resources).
*   **Extensive Training:** Increase the size of `asymp_dataset.json` and perform longer training runs.
*   **Full Multimodal Fine-tuning:** Complete the implementation in `gemma3Training.py` for effective image-to-code learning.
*   **Evaluation:** Develop metrics to assess the quality of generated Asymptote code.

## License

MIT License - see [LICENSE](LICENSE).
